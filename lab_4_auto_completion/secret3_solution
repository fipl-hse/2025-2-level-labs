import math
from lab_4_auto_completion.main import WordProcessor
from lab_3_generate_by_ngrams.main import NGramLanguageModel, BeamSearcher

def solve_secret():
    letter_text = """Dear Harry,
You won’t believe what happened today in the common room.
I was just minding my own business when Malfoy decided to
show up and start one of his usual speeches about "proper
wizarding families." Honestly, you'd think he'd have grown
out of that by now.
At one point he actually said something like, "Mother know
<BURNED>" — whatever that was supposed to mean. He was
trying to insult me, I think, but he got so tied up in his
own smugness that even Pansy looked confused.
Hermione rolled her eyes so hard I thought they'd vanish into
her head, and Ginny nearly hexed him on the spot. I swear,
one day he's going to choke on his own arrogance.
Anyway, hope things are quieter on your end. Let me know
when you're free — we definitely need a proper catch-up.
Your friend,
Ron"""
    
    n_gram_size = 4
    beam_width = 6
    seq_len = 10
    
    word_processor = WordProcessor(end_of_sentence_token='<EOS>')
    
    parts = letter_text.split('<BURNED>')
    before_burned = parts[0]
    
    encoded_sentences = word_processor.encode_sentences(before_burned)
    
    context_encoded = []
    for sentence in encoded_sentences:
        context_encoded.extend(sentence)
    
    all_encoded_words = []
    all_sentences = word_processor.encode_sentences(letter_text.replace('<BURNED>', ''))
    for sentence in all_sentences:
        all_encoded_words.extend(sentence)
    
    mother_id = None
    know_id = None
    for word, word_id in word_processor._storage.items():
        if word == 'mother':
            mother_id = word_id
        elif word == 'know':
            know_id = word_id
    
    if mother_id is not None and know_id is not None:
        start_sequence = (mother_id, know_id)
    else:
        start_sequence = tuple(context_encoded[-(n_gram_size - 1):])
    
    encoded_corpus = tuple(context_encoded)
    language_model = NGramLanguageModel(encoded_corpus, n_gram_size)
    build_result = language_model.build()
    
    if build_result != 0:
        language_model = NGramLanguageModel(tuple(all_encoded_words), n_gram_size)
        language_model.build()
    
    beam_searcher = BeamSearcher(beam_width, language_model)
    
    sequence_candidates = {start_sequence: 0.0}
    
    for _ in range(seq_len):
        new_candidates = {}
        
        for sequence in list(sequence_candidates.keys()):
            next_tokens = beam_searcher.get_next_token(sequence)
            
            if next_tokens:
                updated = beam_searcher.continue_sequence(
                    sequence, next_tokens, {sequence: sequence_candidates[sequence]}
                )
                if updated:
                    new_candidates.update(updated)
        
        if not new_candidates:
            break
        
        sequence_candidates = beam_searcher.prune_sequence_candidates(new_candidates)
        
        if not sequence_candidates:
            break
    
    if sequence_candidates:
        best_sequence = min(sequence_candidates.items(), key=lambda x: x[1])[0]
    else:
        best_sequence = start_sequence
    
    decoded_words = []
    for word_id in best_sequence:
        if word_id in start_sequence and len(decoded_words) < len(start_sequence):
            continue
        word = word_processor.get_element(word_id)
        decoded_words.append(word)
    
    generated_text = ' '.join(decoded_words)
    
    completed_letter = letter_text.replace('<BURNED>', generated_text)
    
    return completed_letter

if __name__ == "__main__":
    completed_letter = solve_secret()
    print(completed_letter)